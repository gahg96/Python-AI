#!/usr/bin/env python3
"""
åˆ†å—åˆå¹¶ä¸´æ—¶æ–‡ä»¶ï¼Œé¿å…å†…å­˜æº¢å‡º
"""

import pandas as pd
from pathlib import Path
import sys

def merge_files_chunked(file_pattern: str, output_file: Path, chunk_size: int = 50, desc: str = ""):
    """åˆ†å—åˆå¹¶æ–‡ä»¶ï¼Œé¿å…å†…å­˜æº¢å‡º"""
    files = sorted(Path('data/historical/temp').glob(file_pattern))
    if not files:
        print(f"  âš ï¸  æœªæ‰¾åˆ°æ–‡ä»¶: {file_pattern}")
        return 0
    
    print(f"  {desc} ({len(files)} ä¸ªæ–‡ä»¶ï¼Œåˆ†å—å¤§å°: {chunk_size})...")
    
    chunks = []
    for i in range(0, len(files), chunk_size):
        chunk_files = files[i:i+chunk_size]
        chunk = pd.concat([pd.read_parquet(f) for f in chunk_files], ignore_index=True)
        chunks.append(chunk)
        if (i // chunk_size + 1) % 5 == 0 or i + chunk_size >= len(files):
            print(f"    è¿›åº¦: {min(i+len(chunk_files), len(files))}/{len(files)}")
    
    # æœ€ç»ˆåˆå¹¶
    print(f"    æœ€ç»ˆåˆå¹¶ä¸­...")
    result = pd.concat(chunks, ignore_index=True)
    n_records = len(result)
    
    # ä¿å­˜
    result.to_parquet(output_file, index=False)
    del chunks, result  # é‡Šæ”¾å†…å­˜
    
    return n_records

if __name__ == '__main__':
    output_dir = Path('data/historical')
    temp_dir = output_dir / 'temp'
    
    if not temp_dir.exists():
        print("âŒ æœªæ‰¾åˆ° temp ç›®å½•")
        sys.exit(1)
    
    print("ğŸ”„ å¼€å§‹åˆ†å—åˆå¹¶ä¸´æ—¶æ–‡ä»¶...")
    print("=" * 60)
    
    # åˆå¹¶å®¢æˆ·æ•°æ®
    n_customers = merge_files_chunked(
        'customers_*.parquet',
        output_dir / 'customers.parquet',
        chunk_size=50,
        desc='åˆå¹¶å®¢æˆ·æ•°æ®'
    )
    print(f"    âœ… å®Œæˆ: {n_customers:,} å®¢æˆ·\n")
    
    # åˆå¹¶è´·æ¬¾æ•°æ®
    n_loans = merge_files_chunked(
        'loans_*.parquet',
        output_dir / 'loan_applications.parquet',
        chunk_size=50,
        desc='åˆå¹¶è´·æ¬¾æ•°æ®'
    )
    print(f"    âœ… å®Œæˆ: {n_loans:,} è´·æ¬¾ç”³è¯·\n")
    
    # åˆå¹¶è¿˜æ¬¾æ•°æ®ï¼ˆä½¿ç”¨æ›´å°çš„åˆ†å—ï¼‰
    n_repayments = merge_files_chunked(
        'repayments_*.parquet',
        output_dir / 'repayment_history.parquet',
        chunk_size=30,  # è¿˜æ¬¾æ–‡ä»¶æ›´å¤§ï¼Œä½¿ç”¨æ›´å°çš„åˆ†å—
        desc='åˆå¹¶è¿˜æ¬¾æ•°æ®'
    )
    print(f"    âœ… å®Œæˆ: {n_repayments:,} è¿˜æ¬¾è®°å½•\n")
    
    print("=" * 60)
    print("âœ… åˆå¹¶å®Œæˆï¼")
    print(f"   å®¢æˆ·: {n_customers:,}")
    print(f"   è´·æ¬¾: {n_loans:,}")
    print(f"   è¿˜æ¬¾: {n_repayments:,}")

