"""äº‘å­˜å‚¨æ•°æ®è®¿é—®æ¨¡å—"""

import os
import hashlib
import requests
from pathlib import Path
from typing import Optional, Dict
import pandas as pd

class CloudStorageDownloader:
    """ä»äº‘å­˜å‚¨ä¸‹è½½æ•°æ®çš„å·¥å…·ç±»"""
    
    def __init__(self, cache_dir: str = "data/cache"):
        """
        åˆå§‹åŒ–ä¸‹è½½å™¨
        
        Args:
            cache_dir: æœ¬åœ°ç¼“å­˜ç›®å½•
        """
        self.cache_dir = Path(cache_dir)
        self.cache_dir.mkdir(parents=True, exist_ok=True)
        
    def download_file(self, url: str, filename: str, force: bool = False) -> Path:
        """
        ä»URLä¸‹è½½æ–‡ä»¶
        
        Args:
            url: æ–‡ä»¶ä¸‹è½½é“¾æ¥
            filename: æœ¬åœ°æ–‡ä»¶å
            force: æ˜¯å¦å¼ºåˆ¶é‡æ–°ä¸‹è½½
            
        Returns:
            ä¸‹è½½åçš„æ–‡ä»¶è·¯å¾„
        """
        file_path = self.cache_dir / filename
        
        # å¦‚æœæ–‡ä»¶å·²å­˜åœ¨ä¸”ä¸å¼ºåˆ¶ä¸‹è½½ï¼Œç›´æ¥è¿”å›
        if file_path.exists() and not force:
            print(f"âœ… ä½¿ç”¨ç¼“å­˜æ–‡ä»¶: {file_path}")
            return file_path
        
        print(f"ğŸ“¥ æ­£åœ¨ä¸‹è½½: {filename}")
        print(f"   æ¥æº: {url}")
        
        try:
            # ä¸‹è½½æ–‡ä»¶ï¼ˆæ”¯æŒå¤§æ–‡ä»¶ï¼‰
            response = requests.get(url, stream=True)
            response.raise_for_status()
            
            total_size = int(response.headers.get('content-length', 0))
            downloaded = 0
            
            with open(file_path, 'wb') as f:
                for chunk in response.iter_content(chunk_size=8192):
                    if chunk:
                        f.write(chunk)
                        downloaded += len(chunk)
                        if total_size > 0:
                            percent = (downloaded / total_size) * 100
                            print(f"\r   è¿›åº¦: {percent:.1f}% ({downloaded}/{total_size} bytes)", end='')
            
            print(f"\nâœ… ä¸‹è½½å®Œæˆ: {file_path}")
            return file_path
            
        except Exception as e:
            print(f"âŒ ä¸‹è½½å¤±è´¥: {e}")
            if file_path.exists():
                file_path.unlink()
            raise
    
    def download_google_drive(self, file_id: str, filename: str, force: bool = False) -> Path:
        """
        ä»Google Driveä¸‹è½½æ–‡ä»¶
        
        Args:
            file_id: Google Driveæ–‡ä»¶ID
            filename: æœ¬åœ°æ–‡ä»¶å
            force: æ˜¯å¦å¼ºåˆ¶é‡æ–°ä¸‹è½½
            
        Returns:
            ä¸‹è½½åçš„æ–‡ä»¶è·¯å¾„
        """
        # Google Driveç›´æ¥ä¸‹è½½é“¾æ¥æ ¼å¼
        url = f"https://drive.google.com/uc?export=download&id={file_id}"
        return self.download_file(url, filename, force)
    
    def download_dropbox(self, share_link: str, filename: str, force: bool = False) -> Path:
        """
        ä»Dropboxä¸‹è½½æ–‡ä»¶
        
        Args:
            share_link: Dropboxåˆ†äº«é“¾æ¥
            filename: æœ¬åœ°æ–‡ä»¶å
            force: æ˜¯å¦å¼ºåˆ¶é‡æ–°ä¸‹è½½
            
        Returns:
            ä¸‹è½½åçš„æ–‡ä»¶è·¯å¾„
        """
        # å°†åˆ†äº«é“¾æ¥è½¬æ¢ä¸ºç›´æ¥ä¸‹è½½é“¾æ¥
        if '?dl=0' in share_link:
            url = share_link.replace('?dl=0', '?dl=1')
        else:
            url = share_link + ('&' if '?' in share_link else '?') + 'dl=1'
        
        return self.download_file(url, filename, force)
    
    def load_parquet(self, file_path: Path) -> pd.DataFrame:
        """
        åŠ è½½Parquetæ–‡ä»¶
        
        Args:
            file_path: æ–‡ä»¶è·¯å¾„
            
        Returns:
            DataFrame
        """
        print(f"ğŸ“– æ­£åœ¨åŠ è½½: {file_path}")
        return pd.read_parquet(file_path)


class DataLoader:
    """æ•°æ®åŠ è½½å™¨ï¼Œæ”¯æŒä»äº‘å­˜å‚¨æˆ–æœ¬åœ°åŠ è½½"""
    
    def __init__(self, config: Optional[Dict] = None):
        """
        åˆå§‹åŒ–æ•°æ®åŠ è½½å™¨
        
        Args:
            config: æ•°æ®æºé…ç½®
        """
        self.config = config or self._load_default_config()
        self.downloader = CloudStorageDownloader()
    
    def _load_default_config(self) -> Dict:
        """åŠ è½½é»˜è®¤é…ç½®"""
        config_path = Path("config/data_sources.yaml")
        if config_path.exists():
            try:
                import yaml
                with open(config_path, 'r', encoding='utf-8') as f:
                    return yaml.safe_load(f) or {}
            except ImportError:
                print("âš ï¸  è­¦å‘Š: PyYAMLæœªå®‰è£…ï¼Œæ— æ³•åŠ è½½é…ç½®æ–‡ä»¶")
                return {}
        return {}
    
    def get_customers(self, use_cache: bool = True) -> pd.DataFrame:
        """è·å–å®¢æˆ·æ•°æ®"""
        return self._load_data('customers', use_cache)
    
    def get_loan_applications(self, use_cache: bool = True) -> pd.DataFrame:
        """è·å–è´·æ¬¾ç”³è¯·æ•°æ®"""
        return self._load_data('loan_applications', use_cache)
    
    def get_repayment_history(self, use_cache: bool = True) -> pd.DataFrame:
        """è·å–è¿˜æ¬¾å†å²æ•°æ®"""
        return self._load_data('repayment_history', use_cache)
    
    def get_macro_economics(self, use_cache: bool = True) -> pd.DataFrame:
        """è·å–å®è§‚ç»æµæ•°æ®"""
        return self._load_data('macro_economics', use_cache)
    
    def _load_data(self, data_name: str, use_cache: bool = True) -> pd.DataFrame:
        """
        åŠ è½½æ•°æ®ï¼ˆä»äº‘å­˜å‚¨æˆ–æœ¬åœ°ï¼‰
        
        Args:
            data_name: æ•°æ®åç§°
            use_cache: æ˜¯å¦ä½¿ç”¨ç¼“å­˜
            
        Returns:
            DataFrame
        """
        # 1. å…ˆæ£€æŸ¥æœ¬åœ°æ–‡ä»¶
        local_path = Path(f"data/historical_backup/{data_name}.parquet")
        if local_path.exists():
            print(f"âœ… ä½¿ç”¨æœ¬åœ°æ–‡ä»¶: {local_path}")
            return self.downloader.load_parquet(local_path)
        
        # 2. æ£€æŸ¥ç¼“å­˜
        cache_path = self.downloader.cache_dir / f"{data_name}.parquet"
        if cache_path.exists() and use_cache:
            print(f"âœ… ä½¿ç”¨ç¼“å­˜æ–‡ä»¶: {cache_path}")
            return self.downloader.load_parquet(cache_path)
        
        # 3. ä»äº‘å­˜å‚¨ä¸‹è½½
        if data_name in self.config:
            source = self.config[data_name]
            source_type = source.get('type', 'url')
            
            if source_type == 'google_drive':
                file_id = source['file_id']
                file_path = self.downloader.download_google_drive(
                    file_id, f"{data_name}.parquet", force=not use_cache
                )
            elif source_type == 'dropbox':
                share_link = source['share_link']
                file_path = self.downloader.download_dropbox(
                    share_link, f"{data_name}.parquet", force=not use_cache
                )
            elif source_type == 'url':
                url = source['url']
                file_path = self.downloader.download_file(
                    url, f"{data_name}.parquet", force=not use_cache
                )
            else:
                raise ValueError(f"ä¸æ”¯æŒçš„æ•°æ®æºç±»å‹: {source_type}")
            
            return self.downloader.load_parquet(file_path)
        
        # 4. å¦‚æœéƒ½æ²¡æœ‰ï¼ŒæŠ›å‡ºé”™è¯¯
        raise FileNotFoundError(
            f"æ— æ³•æ‰¾åˆ°æ•°æ®æ–‡ä»¶: {data_name}.parquet\n"
            f"è¯·æ£€æŸ¥:\n"
            f"  1. æœ¬åœ°æ–‡ä»¶: {local_path}\n"
            f"  2. é…ç½®æ–‡ä»¶: config/data_sources.yaml\n"
            f"  3. æˆ–ä½¿ç”¨è„šæœ¬ç”Ÿæˆæ•°æ®: python3 scripts/generate_dataset.py"
        )


# ä¾¿æ·å‡½æ•°
def load_data(data_name: str, use_cache: bool = True) -> pd.DataFrame:
    """
    ä¾¿æ·å‡½æ•°ï¼šåŠ è½½æ•°æ®
    
    Args:
        data_name: æ•°æ®åç§° (customers, loan_applications, repayment_history, macro_economics)
        use_cache: æ˜¯å¦ä½¿ç”¨ç¼“å­˜
        
    Returns:
        DataFrame
    """
    loader = DataLoader()
    method_map = {
        'customers': loader.get_customers,
        'loan_applications': loader.get_loan_applications,
        'repayment_history': loader.get_repayment_history,
        'macro_economics': loader.get_macro_economics,
    }
    
    if data_name not in method_map:
        raise ValueError(f"æœªçŸ¥çš„æ•°æ®åç§°: {data_name}")
    
    return method_map[data_name](use_cache)

