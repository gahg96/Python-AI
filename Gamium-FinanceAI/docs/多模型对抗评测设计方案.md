# 多模型对抗评测系统设计方案

## 一、整体架构设计

### 1.1 系统定位
在金融场景中，银行需要在智能问数、客户咨询、贷款审批、营销沟通等场景中，统一评测不同大模型和智能体的表现。Gamium 提供回合制自动对话和任务执行能力，量化评估关键指标，支持AB测试。

### 1.2 核心功能模块

```
┌─────────────────────────────────────────────────────────────┐
│                    多模型对抗评测平台                          │
├─────────────────────────────────────────────────────────────┤
│                                                               │
│  ┌──────────────┐  ┌──────────────┐  ┌──────────────┐     │
│  │  模型接入层   │  │  评测引擎层   │  │  指标计算层   │     │
│  │              │  │              │  │              │     │
│  │ • 统一网关    │  │ • 回合制对抗  │  │ • 正确率      │     │
│  │ • 模型管理    │  │ • 脚本驱动    │  │ • 幻觉率      │     │
│  │ • 协议适配    │  │ • 任务执行    │  │ • 合规率      │     │
│  └──────────────┘  └──────────────┘  └──────────────┘     │
│                                                               │
│  ┌──────────────┐  ┌──────────────┐  ┌──────────────┐     │
│  │  样本管理     │  │  结果分析     │  │  AB测试      │     │
│  │              │  │              │  │              │     │
│  │ • 样本库      │  │ • 对比报告    │  │ • 分组测试    │     │
│  │ • 样本生成    │  │ • 可视化      │  │ • 统计分析    │     │
│  │ • 样本迭代    │  │ • 导出功能    │  │ • 决策支持    │     │
│  └──────────────┘  └──────────────┘  └──────────────┘     │
│                                                               │
└─────────────────────────────────────────────────────────────┘
```

## 二、详细设计

### 2.1 模型接入层

#### 2.1.1 统一网关设计
```python
class ModelGateway:
    """统一模型网关，支持多种模型接入"""
    
    def __init__(self):
        self.models = {}  # 模型注册表
        self.adapters = {}  # 协议适配器
    
    def register_model(self, model_id, model_type, config):
        """注册模型
        - model_type: 'openai', 'anthropic', 'local_llm', 'rag', 'agent'
        - config: API密钥、端点、参数等
        """
        pass
    
    def call_model(self, model_id, prompt, context=None):
        """统一调用接口，自动适配不同模型协议"""
        pass
```

#### 2.1.2 支持的模型类型
- **大语言模型**: OpenAI GPT, Claude, 文心一言, 通义千问等
- **RAG应用**: 基于向量数据库的检索增强生成
- **智能体**: LangChain Agent, AutoGPT等
- **本地模型**: 私有部署的模型

#### 2.1.3 协议适配
- OpenAI兼容API
- 自定义HTTP API
- gRPC接口
- WebSocket实时流式

### 2.2 评测引擎层

#### 2.2.1 回合制对抗设计
```python
class AdversarialEvaluator:
    """回合制对抗评测引擎"""
    
    def __init__(self, models, test_cases):
        self.models = models  # 参与评测的模型列表
        self.test_cases = test_cases  # 测试用例
        self.results = []  # 评测结果
    
    def run_evaluation(self):
        """执行评测流程"""
        for test_case in self.test_cases:
            for model in self.models:
                result = self._evaluate_model(model, test_case)
                self.results.append(result)
    
    def _evaluate_model(self, model, test_case):
        """单个模型评测"""
        # 1. 发送初始提示
        # 2. 接收模型响应
        # 3. 根据脚本执行多轮对话
        # 4. 收集指标数据
        pass
```

#### 2.2.2 脚本驱动机制
```yaml
# 评测脚本示例
test_case:
  id: "loan_approval_001"
  scenario: "贷款审批咨询"
  initial_prompt: "我想申请一笔50万元的个人贷款"
  
  rounds:
    - role: "user"
      action: "ask"
      content: "需要什么条件？"
      expected_keywords: ["收入", "信用", "担保"]
    
    - role: "user"
      action: "challenge"
      content: "我的信用记录不太好，还能申请吗？"
      expected_behavior: "合规拒绝或风险提示"
    
    - role: "user"
      action: "verify"
      content: "你刚才说的利率是多少？"
      expected_consistency: true  # 检查是否与之前回答一致
```

#### 2.2.3 任务执行能力
- **对话任务**: 多轮问答、上下文理解
- **计算任务**: 利率计算、风险评估
- **检索任务**: 知识库查询、文档检索
- **决策任务**: 审批决策、推荐建议

### 2.3 指标计算层

#### 2.3.1 核心指标定义

**1. 正确率 (Accuracy)**
```python
def calculate_accuracy(model_responses, ground_truth):
    """计算回答正确率"""
    correct = 0
    for response, truth in zip(model_responses, ground_truth):
        if evaluate_answer(response, truth):
            correct += 1
    return correct / len(model_responses)
```

**2. 幻觉率 (Hallucination Rate)**
```python
def calculate_hallucination_rate(model_responses, knowledge_base):
    """计算幻觉率 - 模型生成无法验证或错误的信息比例"""
    hallucination_count = 0
    for response in model_responses:
        if detect_hallucination(response, knowledge_base):
            hallucination_count += 1
    return hallucination_count / len(model_responses)
```

**3. 合规命中率 (Compliance Rate)**
```python
def calculate_compliance_rate(model_responses, compliance_rules):
    """计算合规命中率 - 符合金融监管要求的回答比例"""
    compliance_count = 0
    for response in model_responses:
        if check_compliance(response, compliance_rules):
            compliance_count += 1
    return compliance_count / len(model_responses)
```

**4. 响应延时 (Response Latency)**
```python
def measure_latency(model_id, prompt):
    """测量响应延时"""
    start_time = time.time()
    response = call_model(model_id, prompt)
    end_time = time.time()
    return end_time - start_time
```

**5. 一致性 (Consistency)**
```python
def calculate_consistency(model_responses):
    """计算多轮对话中的一致性"""
    # 检查相同问题是否得到一致回答
    # 检查上下文是否连贯
    pass
```

**6. 用户体验指标**
- 回答流畅度
- 专业术语使用准确性
- 情感表达适当性

### 2.4 样本管理

#### 2.4.1 样本库结构
```python
class SampleLibrary:
    """样本库管理"""
    
    def __init__(self):
        self.positive_samples = []  # 正向样本（标准答案）
        self.negative_samples = []  # 负向样本（错误案例）
        self.adversarial_samples = []  # 对抗样本（边界情况）
    
    def add_sample(self, sample_type, content, metadata):
        """添加样本"""
        pass
    
    def generate_adversarial_sample(self, base_sample):
        """生成对抗样本"""
        # 通过改写、添加噪声等方式生成
        pass
```

#### 2.4.2 样本分类
- **场景分类**: 智能问数、客户咨询、贷款审批、营销沟通
- **难度分类**: 简单、中等、困难、极端
- **类型分类**: 事实性、推理性、创造性、合规性

### 2.5 AB测试支持

#### 2.5.1 测试设计
```python
class ABTestManager:
    """AB测试管理器"""
    
    def create_test(self, test_name, models, sample_distribution):
        """创建AB测试"""
        # sample_distribution: {'model_a': 0.5, 'model_b': 0.5}
        pass
    
    def assign_sample(self, test_id, sample):
        """分配样本到测试组"""
        # 根据分配比例随机分配
        pass
    
    def analyze_results(self, test_id):
        """分析AB测试结果"""
        # 统计显著性检验
        # 效果对比分析
        pass
```

## 三、系统集成方案

### 3.1 与现有系统集成

#### 3.1.1 在Gamium Finance AI中的位置
- **新增页面**: "模型评测" 页面
- **集成点**: 
  - 客户预测页面：可以评测不同模型对客户风险评估的准确性
  - 周期分析页面：可以评测不同模型对经济周期判断的一致性
  - 风控压测页面：可以评测不同模型在压力场景下的表现

#### 3.1.2 数据流设计
```
用户输入 → 模型网关 → 多个模型并行调用 → 结果收集 → 指标计算 → 对比展示
```

### 3.2 前端界面设计

#### 3.2.1 主要页面
1. **模型管理页面**
   - 模型注册/配置
   - 模型状态监控
   - 模型性能概览

2. **评测任务页面**
   - 创建评测任务
   - 选择模型和样本
   - 配置评测参数
   - 任务执行监控

3. **结果对比页面**
   - 多模型对比表格
   - 指标可视化图表
   - 详细报告下载

4. **样本管理页面**
   - 样本库浏览
   - 样本添加/编辑
   - 样本分类管理

### 3.3 后端API设计

```python
# 模型管理
POST /api/models/register          # 注册模型
GET  /api/models/list              # 获取模型列表
GET  /api/models/{id}/status       # 获取模型状态

# 评测任务
POST /api/evaluation/create        # 创建评测任务
GET  /api/evaluation/{id}/status   # 获取任务状态
POST /api/evaluation/{id}/start    # 启动评测
GET  /api/evaluation/{id}/results  # 获取评测结果

# 样本管理
GET  /api/samples/list             # 获取样本列表
POST /api/samples/add              # 添加样本
POST /api/samples/generate         # 生成对抗样本

# AB测试
POST /api/abtest/create            # 创建AB测试
GET  /api/abtest/{id}/results      # 获取AB测试结果
```

## 四、实施步骤

### 阶段一：基础框架（1-2周）
1. 实现模型网关基础功能
2. 支持OpenAI API接入
3. 实现简单的评测流程
4. 基础指标计算

### 阶段二：评测引擎（2-3周）
1. 实现回合制对话机制
2. 脚本驱动系统
3. 多模型并行评测
4. 完整指标计算

### 阶段三：样本与AB测试（1-2周）
1. 样本库管理系统
2. 对抗样本生成
3. AB测试框架
4. 统计分析功能

### 阶段四：界面与集成（1-2周）
1. 前端界面开发
2. 与现有系统集成
3. 报告生成与导出
4. 性能优化

## 五、技术选型

### 5.1 后端技术
- **框架**: Flask (与现有系统一致)
- **异步处理**: Celery + Redis (处理长时间评测任务)
- **模型调用**: httpx (异步HTTP客户端)
- **数据存储**: SQLite/PostgreSQL (评测结果存储)

### 5.2 前端技术
- **框架**: 与现有系统一致 (原生HTML/JS)
- **可视化**: Chart.js (指标图表)
- **UI组件**: 复用现有组件库

### 5.3 评测工具
- **文本相似度**: sentence-transformers
- **幻觉检测**: 基于知识库验证 + LLM判断
- **合规检查**: 规则引擎 + 关键词匹配

## 六、关键挑战与解决方案

### 6.1 模型调用延迟
- **问题**: 不同模型响应时间差异大
- **解决**: 异步并行调用 + 超时控制

### 6.2 指标计算准确性
- **问题**: 主观性指标难以量化
- **解决**: 多维度评估 + 人工标注验证

### 6.3 样本质量
- **问题**: 需要高质量、多样化的测试样本
- **解决**: 样本生成工具 + 社区贡献机制

### 6.4 成本控制
- **问题**: 大模型API调用成本高
- **解决**: 缓存机制 + 批量处理 + 成本监控

## 七、未来扩展

1. **自动化样本生成**: 使用LLM生成测试样本
2. **实时评测**: 支持生产环境实时监控
3. **模型微调建议**: 基于评测结果给出优化建议
4. **多模态支持**: 支持图像、语音等多模态评测
5. **联邦评测**: 支持跨机构模型评测

