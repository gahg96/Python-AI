# AI演武场完整功能说明

## 一、系统概述

AI演武场是一个多模型/多策略对比评测平台，用于在统一的客户池和宏观环境下，评估不同贷款审批策略的表现。系统支持规则引擎、评分系统、多轮模拟、多智能体博弈、LLM集成等完整功能。

## 二、核心功能模块

### 1. 规则引擎 (Rule Engine)

**功能描述：**
- 支持条件-动作-惩罚配置
- 动态调整审批阈值、利差、贷款金额等参数
- 支持强制通过/拒绝、抵押担保要求等风险控制措施
- 规则优先级和启用/禁用控制

**参数说明：**

#### 条件参数
- **字段选择**：月收入、年龄、负债率、信用分、经营年限、年收入、总资产、存款余额、历史贷款数、最大逾期天数、风险评分
- **操作符**：>、>=、<、<=、==、!=、in、not_in、contains
- **逻辑组合**：支持AND逻辑（多个条件需同时满足）

#### 动作参数
- **审批相关**：
  - `approval_threshold_delta`: 审批阈值调整（-0.1到0.1）
  - `rate_spread_delta`: 利差调整（-0.01到0.01）
  - `loan_amount_multiplier`: 贷款金额倍数（0.5到2.0）
  - `term_months_delta`: 期限调整（-12到12个月）
- **贷款限制**：
  - `min_loan_amount`: 最小贷款金额（0表示不限制）
  - `max_loan_amount`: 最大贷款金额（0表示不限制）
- **风险控制**：
  - `require_collateral`: 要求抵押（true/false）
  - `require_guarantor`: 要求担保（true/false）
  - `collateral_ratio`: 抵押物价值比例要求（0.0到1.0）
  - `guarantor_credit_min`: 担保人最低信用分
- **强制决策**：
  - `force_approve`: 强制通过
  - `force_reject`: 强制拒绝

#### 惩罚参数
- **评分调整**：
  - `score_delta`: 综合评分调整（-1.0到1.0）
  - `profit_score_delta`: 利润得分调整
  - `risk_score_delta`: 风险得分调整
  - `compliance_score_delta`: 合规得分调整
- **风险调整**：
  - `risk_multiplier`: 风险倍数（0.5到2.0）
  - `default_prob_multiplier`: 违约概率倍数
- **利润调整**：
  - `profit_discount`: 利润折扣（0.0到1.0）
  - `interest_rate_bonus`: 利率加成（-0.05到0.05）

**默认规则模板：**
系统提供7条常用规则，可直接使用：
1. 高收入客户优惠
2. 高风险客户拒绝
3. 优质信用客户
4. 低龄客户限制
5. 企业客户优惠
6. 大额贷款审核
7. 黑名单客户拒绝

### 2. 评分系统 (Scoring System)

**六维度评分：**
1. **利润得分** (30%)：基于预估利润，归一化到[0,1]
2. **风险得分** (30%)：基于违约概率，违约率越低得分越高
3. **稳定性得分** (10%)：基于利润波动率和最大回撤
4. **合规得分** (20%)：基于违规次数，违规越少得分越高
5. **效率得分** (5%)：基于响应延迟，延迟越低得分越高
6. **可解释性得分** (5%)：基于规则覆盖率和触发次数

**综合得分计算：**
```
综合得分 = 利润得分×30% + 风险得分×30% + 稳定性得分×10% + 
          合规得分×20% + 效率得分×5% + 可解释性得分×5%
```

### 3. 单场演武场

**功能：**
- 多个参赛者（策略/模型）在同一批客户上对比
- 支持自定义参赛者参数（审批阈值、利差、模型ID）
- 支持规则引擎配置
- 支持压力情景和黑天鹅事件
- 返回详细的评分分解和触发规则统计

**API端点：** `POST /api/arena/run`

### 4. 多轮多场景演武场

**功能：**
- 支持多轮模拟（可配置回合数）
- 支持场景序列（normal/stress交替）
- 支持黑天鹅事件指定回合
- 累积得分和排名
- 完整的回放数据

**API端点：** `POST /api/arena/multi-round`

### 5. 多智能体博弈

**功能：**
- 多个智能体竞争同一批客户
- 支持不同策略（aggressive/rule_based/conservative）
- 竞价机制：多个智能体都批准时，利润最高者获胜
- 锦标赛模式：多轮竞争，累积得分排名
- 详细的决策理由和竞争过程

**API端点：** `POST /api/arena/tournament`

### 6. LLM集成

**功能：**
- 通过model_id调用真实LLM进行决策
- 支持模型网关中的18个模型
- 生成决策理由和风险评估
- 可扩展接入AlphaZero等强化学习策略

**API端点：** `POST /api/arena/llm-decision`

### 7. 可视化与解释

**功能：**
- **AI解释**：智能分析胜者、性能对比、关键洞察、风险评估、建议
- **计算说明**：详细的公式和计算步骤
- **规则触发**：每个客户触发的规则列表
- **图表可视化**：
  - 雷达图：六维度评分对比
  - 柱状图：利润对比
  - 回撤曲线：风险波动趋势

### 8. 回放系统

**功能：**
- 逐客户回放：查看每个客户的决策详情
- 规则触发统计：查看规则使用情况
- 决策理由展示：每个决策的详细原因
- 支持按参赛者筛选

### 9. 导出报告

**支持格式：**
- JSON：完整数据结构
- CSV：表格数据
- TXT：文本报告
- HTML：格式化网页报告

## 三、业务场景应用

### 场景1：策略优化

**问题：** 银行需要优化贷款审批策略，在风险可控的前提下提高利润。

**解决方案：**
1. 创建多个策略变体（不同审批阈值、利差）
2. 在同一批客户上运行演武场
3. 对比综合得分，选择最优策略
4. 分析规则触发情况，优化规则配置

**示例：**
```json
{
  "participants": [
    {"name": "当前策略", "approval_threshold": 0.18, "rate_spread": 0.015},
    {"name": "优化策略1", "approval_threshold": 0.16, "rate_spread": 0.012},
    {"name": "优化策略2", "approval_threshold": 0.20, "rate_spread": 0.018}
  ],
  "customer_count": 1000,
  "rules": [...]  // 加载默认规则或自定义规则
}
```

### 场景2：压力测试

**问题：** 评估策略在不同经济环境下的表现。

**解决方案：**
1. 配置多轮模拟，设置场景序列
2. 在特定回合注入黑天鹅事件
3. 观察策略的稳定性和恢复能力
4. 分析最大回撤和恢复时间

**示例：**
```json
{
  "rounds": 12,
  "scenario_sequence": ["normal", "stress", "normal", "stress"],
  "black_swan_rounds": [6, 12],
  "participants": [...]
}
```

### 场景3：模型对比

**问题：** 对比不同AI模型在贷款审批中的表现。

**解决方案：**
1. 为每个模型配置策略参数
2. 运行演武场，对比审批率、违约率、利润
3. 分析模型决策的一致性
4. 选择最适合业务场景的模型

**示例：**
```json
{
  "participants": [
    {"name": "GPT-4策略", "model_id": "gpt-4", "approval_threshold": 0.18},
    {"name": "Claude策略", "model_id": "claude-3-opus", "approval_threshold": 0.18},
    {"name": "规则策略", "approval_threshold": 0.18}
  ]
}
```

### 场景4：规则引擎调优

**问题：** 优化规则配置，提高审批效率和风险控制。

**解决方案：**
1. 加载默认规则模板
2. 根据业务需求调整规则参数
3. 运行演武场，观察规则触发情况
4. 分析规则对利润和风险的影响
5. 迭代优化规则配置

### 场景5：多智能体竞争

**问题：** 模拟多个银行/部门竞争同一批客户。

**解决方案：**
1. 配置多个智能体（不同策略）
2. 运行锦标赛模式
3. 观察竞争过程和获胜策略
4. 分析不同策略的竞争优势

## 四、技术架构

### 后端架构

```
app.py (Flask API)
├── /api/arena/run (单场演武场)
├── /api/arena/multi-round (多轮演武场)
├── /api/arena/tournament (多智能体博弈)
├── /api/arena/llm-decision (LLM决策)
├── /api/arena/ai-explain (AI解释)
├── /api/arena/export (导出报告)
└── /api/arena/default-rules (默认规则)

src/arena/
├── rule_engine.py (规则引擎)
├── scoring_system.py (评分系统)
├── multi_round_simulator.py (多轮模拟器)
└── multi_agent_game.py (多智能体博弈)
```

### 前端架构

```
web/index.html
├── 演武场模态框
│   ├── 参赛者配置
│   ├── 规则引擎配置
│   ├── 全局参数配置
│   └── 结果展示
├── AI解释模态框
├── 回放模态框
├── 图表可视化
└── 导出功能
```

## 五、使用流程

### 1. 基础使用

1. 打开系统，进入"AI演武场"
2. 配置参赛者（名称、审批阈值、利差、模型ID）
3. 点击"加载默认规则"或自定义规则
4. 设置全局参数（客户数、贷款额、基准利率等）
5. 选择场景（正常/压力）和黑天鹅选项
6. 点击"运行PK"
7. 查看结果表格和评分分解
8. 点击"AI解释"查看智能分析
9. 点击"回放"查看详细决策过程
10. 点击"图表"查看可视化分析
11. 导出报告（JSON/CSV/TXT/HTML）

### 2. 高级使用

**多轮模拟：**
- 配置回合数和场景序列
- 指定黑天鹅事件发生的回合
- 观察累积得分和排名变化

**多智能体博弈：**
- 配置多个智能体和策略
- 运行锦标赛模式
- 分析竞争过程和获胜策略

**LLM集成：**
- 选择模型ID
- 调用LLM进行决策
- 获取决策理由和风险评估

## 六、数据说明

### 输入数据

- **参赛者配置**：名称、审批阈值、利差、模型ID（可选）
- **规则配置**：条件、动作、惩罚参数
- **全局参数**：客户数、贷款额、基准利率、种子、场景

### 输出数据

- **结果表格**：排名、审批率、违约概率、利润、RAROC、评分分解
- **触发规则**：每个规则被触发的次数
- **客户详情**：每个客户的决策详情和触发规则
- **评分分解**：六维度得分和综合得分
- **回放数据**：完整的决策过程

## 七、最佳实践

1. **规则配置**：
   - 从默认规则开始，逐步优化
   - 设置合理的优先级
   - 定期审查和更新规则

2. **策略对比**：
   - 使用相同的客户池和种子，确保公平对比
   - 运行多次，取平均值
   - 关注综合得分，而非单一指标

3. **压力测试**：
   - 定期运行压力情景测试
   - 监控最大回撤和恢复时间
   - 准备应急预案

4. **模型选择**：
   - 对比多个模型的综合表现
   - 考虑延迟和成本因素
   - 结合业务场景选择最适合的模型

## 八、常见问题

**Q: 如何添加自定义规则？**
A: 点击"+ 添加规则"，配置条件、动作和惩罚参数，所有参数都有默认值。

**Q: 规则优先级如何工作？**
A: 数字越大优先级越高，高优先级规则先执行，可以覆盖低优先级规则的效果。

**Q: 如何理解评分分解？**
A: 六维度评分分别反映不同方面的表现，综合得分是加权平均，用于总体排名。

**Q: 多智能体博弈和单场演武场的区别？**
A: 单场演武场是并行对比，每个参赛者独立决策；多智能体博弈是竞争模式，多个智能体竞争同一批客户。

**Q: 如何接入真实LLM？**
A: 在参赛者配置中选择模型ID，系统会自动调用模型网关进行决策。

## 九、未来扩展

1. **强化学习集成**：接入AlphaZero等RL算法，实现自我学习
2. **实时决策**：支持实时客户流和在线决策
3. **A/B测试**：支持生产环境的A/B测试
4. **规则自动生成**：基于历史数据自动生成优化规则
5. **多目标优化**：支持多目标（利润、风险、合规）的帕累托优化

